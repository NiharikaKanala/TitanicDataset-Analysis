{"cells":[{"metadata":{"_uuid":"d37e83e0-7ec3-4327-9ade-effc9d5bce0a","_cell_guid":"cad683ef-0219-401b-a6d8-40df0de8f76c","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport random as rd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport re\nfrom pandas.plotting import scatter_matrix\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold,train_test_split,KFold\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import LinearSVC, SVC\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n#LOAD DATA\ntrain_df = pd.read_csv('../input/train.csv')\ntest_df = pd.read_csv('../input/test.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()\ntrain_df.info() #We have Sex, Ticket, Cabin, Embarked as categorical\ntrain_df.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.isnull(train_df).sum() #Identify null values in training dataset\n#pd.isnull(test_df).sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = train_df.groupby(['Survived','Sex'])['Survived'].count().unstack('Sex') #There is good chance females survive\ndf1.plot(kind='bar',stacked=True,)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['Ticket'].head(10) #Not a useful measure.\ntrain_df.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[['Embarked','Survived']].groupby('Embarked')['Survived'].value_counts().unstack('Survived').plot(kind = 'bar',stacked=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[['Pclass','Survived']].groupby('Pclass')['Survived'].value_counts().unstack('Survived').plot(kind='bar',stacked=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.corr()\nsns.pairplot(train_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    **Feature Engineering and Visualization**"},{"metadata":{},"cell_type":"markdown","source":"Looks like Srivived, Pclass, SibSp, Parch are categorical"},{"metadata":{"trusted":true},"cell_type":"code","source":"combine = [train_df,test_df]\n\nfor data in combine:\n    for i in range(0,len(data)):\n        data['Name'].iloc[i] = re.search('([a-zA-Z]+)\\.',data['Name'].iloc[i]).group(0)\n    data['Name'] = data['Name'].replace(r'\\.','',regex=True)\n\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['Name'].value_counts()\npd.crosstab(train_df['Name'],train_df['Sex'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combine = [train_df,test_df]\nfor data in combine: \n    data['Name'] = data['Name'].replace(['Capt','Col','Don','Dr','Jonkheer','Lady','Major','Rev','Sir','Countess'],'Others')\n    data['Name'] = data['Name'].replace(['Mlle','Ms'],'Miss')\n    data['Name'] = data['Name'].replace(['Mme'],'Mrs')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[['Name','Survived']].groupby('Name').mean()*100 #Average Survival Rate","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plt.barh(train_df['Parch'].value_counts().index,train_df['Parch'].value_counts().values)\ntrain_df['Parch'].value_counts().plot(kind='barh') #People traveling alone are more, hence there is higher chance of survivng","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['SibSp'].value_counts()  \ntrain_df[['SibSp','Survived']].groupby('SibSp')['Survived'].value_counts().unstack('Survived').plot(kind='bar',stacked='True')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combine = [train_df,test_df]\nfor data in combine: \n    data['isAlone'] = 0\n    for i in range(len(data)):\n        if data['SibSp'].iloc[i] > 0 or data['Parch'].iloc[i] > 0:\n            data['isAlone'].iloc[i] = 1\n    data['FamSize'] = data['SibSp'] + data['Parch'] + 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['Cabin'].value_counts() #Come back later and see if we can get anything out of cabin ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[['Fare','Survived']].groupby('Survived')['Fare'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_df[['Fare','Pclass']].groupby('Pclass')['Fare'].mean())\nprint(train_df[['Fare','Pclass']].groupby('Pclass')['Fare'].median())\n\ntrain_df[['Fare','Pclass']].boxplot(by='Pclass')#Data with fare>200 seems to be like outliers\n\n#train_df['FareClass'] = pd.qcut(train_df['Fare'],4)\n#train_df['FareClass'].value_counts()\n\n#train_df[train_df['Fare']>=200].count() #There are 20 such data points and they must be millionaries dropping them\n#test_df[train_df['Fare']>=200].count()\n\ntrain_df = train_df[train_df['Fare']<200] #In fare there are outliers. Eliminating those data points\ntest_df[test_df['Fare']>200]['Fare'] = train_df[train_df['Pclass']==1]['Fare'].mean() \n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[['Fare','Pclass']].boxplot(by='Pclass')#Data with fare>200 seems to be like outliers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.isnull(train_df['Fare']).sum()\npd.isnull(test_df['Fare']).sum()\n\ntest_df['Fare'] = test_df['Fare'].apply(lambda x: train_df['Fare'].mean() if pd.isna(x) else x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combine = [train_df,test_df]\n\nfor data in combine:\n    data['Fare1'] = 0\n    for i in range(len(data)):\n        #print(data['Fare'].iloc[i])\n        #if data['Fare'].iloc[i] <= 12.5:\n        #    data['Fare1'].iloc[i] = 0\n        #elif data['Fare'].iloc[i] > 12.5 and data['Fare'].iloc[i] <=25:\n        #    data['Fare1'].iloc[i] = 1\n        #else:\n        #    data['Fare1'].iloc[i] = 2\n        #print(data['Fare1'].iloc[i])\n\n        if data['Fare'].iloc[i] <= 7.91:\n            data['Fare1'].iloc[i] = 0\n        elif data['Fare'].iloc[i] > 7.91 and data['Fare'].iloc[i] <= 14.45:\n            data['Fare1'].iloc[i] = 1\n        elif data['Fare'].iloc[i] > 14.45 and data['Fare'].iloc[i] <= 31:\n            data['Fare1'].iloc[i] = 2\n        else:\n            data['Fare1'].iloc[i] = 3\n#train_df['Fare'].value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.isna(train_df).sum() #There are missing values in age and embarked\n\ncombine = [train_df, test_df]\nfor data in combine:    \n    data['Age'] = data['Age'].apply(lambda x: train_df['Age'].mean() if pd.isna(x) else x)\n    data['Embarked'] = data['Embarked'].apply(lambda x: train_df['Embarked'].mode()[0] if pd.isna(x) else x)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['Age'].hist()\n#train_df['AgeGroup'] = pd.cut(train_df['Age'],5)\n#train_df['AgeGroup'].value_counts()\n\n#combine = [train_df,test_df]\n\n#pd.isna(test_df['AgeGroup']).sum()\n#train_df[pd.isna(train_df['AgeGroup'])]\n    \nbins = [0,16,32,48,64,np.inf]\n#labels = ['Baby','Teens','Youth','YoungAdults','Adults']\n#train_df['AgeGroup'] = pd.cut(train_df['Age'],bins,labels=labels)\n#test_df['AgeGroup'] = pd.cut(test_df['Age'],bins,labels=labels)\n\n#bins = [0,10,20,30,50,np.inf]\nlabels = ['Child','Youth','Young Adults','Adults','Old']\ntrain_df['AgeGroup'] = pd.cut(train_df['Age'],bins,labels=labels)\n\ntest_df['AgeGroup'] = pd.cut(test_df['Age'],bins,labels=labels)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplot(1,2,1)\nplt.title('Survived = 0')\ntrain_df[train_df['Survived']==0]['Fare'].hist()\nplt.subplot(1,2,2)\nplt.title('Survived = 1')\ntrain_df[train_df['Survived']==1]['Fare'].hist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Catergorical Variable creation "},{"metadata":{"trusted":true},"cell_type":"code","source":"sex_map = {'male':1,'female':0}\n#train_df1 = train_df.copy()\ntrain_df['Sex'] = train_df['Sex'].map(sex_map)\ntest_df['Sex'] =test_df['Sex'].map(sex_map)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.isna(train_df['Sex']).sum() #To check if there are any NUll values present\nembark_map = {'C':2,'Q':1, 'S':0}\ntrain_df['Embarked'] = train_df['Embarked'].map(embark_map)\ntest_df['Embarked'] = test_df['Embarked'].map(embark_map)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Label = LabelEncoder()\ntrain_df['Name']= Label.fit_transform(train_df['Name'])\ntest_df['Name']= Label.fit_transform(test_df['Name'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Age_label = LabelEncoder()\n#pd.isna(train_df['AgeGroup']).sum()\n\n#train_df['AgeGroup'] = Age_label.fit_transform(train_df['AgeGroup'])\n#train_df['AgeGroup'].value_counts()\n#test_df['AgeGroup'] = Age_label.fit_transform(test_df['AgeGroup'])\n\n#train_df['Age'] = train_df['AgeGroup']*train_df['Pclass']\n#test_df['Age'] = test_df['AgeGroup']*test_df['Pclass']\n\n#train_df['Age'].value_counts() #What happened to 5 & 11\ntrain_df['AgeGroup'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combine = [train_df,test_df]\nfor data in combine:\n    for i in range(len(data)):\n        if data['AgeGroup'].iloc[i] == 'Child':\n            data['Age'].iloc[i] = 0\n        elif data['AgeGroup'].iloc[i] == 'Youth':\n            data['Age'].iloc[i] = 1\n        elif data['AgeGroup'].iloc[i] == 'Young Adults':\n            data['Age'].iloc[i] = 2\n        elif data['AgeGroup'].iloc[i] == 'Adults':\n            data['Age'].iloc[i] = 3\n        else:\n            data['Age'].iloc[i] = 4\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_df['AgeGroup'].value_counts()\ntrain_df.drop(['Ticket','Cabin','PassengerId','Fare','SibSp','Parch','AgeGroup','Pclass'],axis=1,inplace=True)\ntest_df.drop(['Ticket','Cabin','Fare','SibSp','Parch','AgeGroup','Pclass'],axis=1,inplace=True)\n\n#train_df.drop(['FareClass'],axis=1,inplace=True)\n#test_df.drop(['FareClass'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Building models**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head() #Try converting categorical feature columns to objects","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Split = StratifiedKFold()\ntarget = train_df['Survived']\nInput = train_df.drop(['Survived'],axis=1)\nx_train,x_val,y_train,y_val = train_test_split(Input,target,random_state = 1000, test_size = 0.33)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"LOGISTIC REGRESSION"},{"metadata":{"trusted":true},"cell_type":"code","source":"log_model = LogisticRegression()\nlog_model.fit(x_train,y_train)\ny_pred1 = log_model.predict(x_val)\nacc_log = round(accuracy_score(y_pred1,y_val)*100,2)\nacc_log","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.barh(x_train.columns.values,(np.round((log_model.coef_),2))[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RANDOM FOREST CLASSIFIER"},{"metadata":{"trusted":true},"cell_type":"code","source":"rand_model = RandomForestClassifier()\nrand_model.fit(x_train,y_train)\ny_pred2 = rand_model.predict(x_val)\nacc_rand = round(accuracy_score(y_pred2,y_val)*100,4)\nprint(\"Accuracy Calculation\",acc_rand)\nround(rand_model.score(x_train,y_train),4)*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col = pd.Series(x_train.columns.values)\nimp = pd.Series(rand_model.feature_importances_)\nfeatures = pd.concat([col,imp],axis=1,keys=['Features','Values'])\nplt.barh(features['Features'],features['Values'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**DECISION TREES**"},{"metadata":{"trusted":true},"cell_type":"code","source":"DT_model = DecisionTreeClassifier()\nDT_model.fit(x_train,y_train)\ny_pred3 = DT_model.predict(x_val)\nacc_DT = np.round(accuracy_score(y_pred3,y_val),4)*100\nacc_DT\n#DT_model.score(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**KNN Classifier**"},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_model = KNeighborsClassifier()\nknn_model.fit(x_train,y_train)\ny_pred4 = knn_model.predict(x_val)\nacc_knn = np.round(accuracy_score(y_pred4,y_val),4)*100\nacc_knn","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Support Vector Machines**"},{"metadata":{"trusted":true},"cell_type":"code","source":"suppv = SVC()\nsuppv.fit(x_train,y_train)\ny_pred5 = suppv.predict(x_test)\nacc_sv = round(accuracy_score(y_pred5,y_test)*100,2)\nacc_sv","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Naive Bayes Classifier**"},{"metadata":{"trusted":true},"cell_type":"code","source":"nb_mod = GaussianNB()\nnb_mod.fit(x_train,y_train)\ny_pred6 = nb_mod.predict(x_test)\nacc_nb = round(accuracy_score(y_pred6,y_test)*100,2)\nacc_nb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_accuracies = pd.DataFrame({'Model':['Logistic Regression','Random Forests','Decision Tree','Knn Classifier','SVM','Naive Bayes'],\n                                 'Accuracy':[acc_log,acc_rand,acc_DT,acc_knn,acc_sv,acc_nb]})\nmodel_accuracies.sort_values(by='Accuracy',ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_sub1 = rand_model.predict(test_df.iloc[:,1:])\ny_sub2 = suppv.predict(test_df.iloc[:,1:])\n\nsubmission = pd.DataFrame({'PassengerId':test_df['PassengerId'],'Survived':y_sub1})\nsubmission.to_csv('./submission_rand.csv', index=False)\n\nsubmission = pd.DataFrame({'PassengerId':test_df['PassengerId'],'Survived':y_sub2})\nsubmission.to_csv('./submission_supvec.csv', index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Kf = KFold(n_splits=3,random_state=1000,shuffle=False)\ntarget = train_df['Survived']\ntrain_df.drop(['Survived'],axis=1,inplace=True)\n\nmod_acc = []\nmod_features = []\n\nfor train_index, test_index in Kf.split(train_df):\n    x_train, y_train = train_df[train_index[0]:train_index[-1]], target[train_index[0]:train_index[-1]]\n    x_test, y_test = train_df[test_index[0]:test_index[-1]], target[test_index[0]:test_index[-1]]\n    randForest = RandomForestClassifier()\n    randForest.fit(x_train,y_train)\n    y_pred = randForest.predict(x_test)\n    mod_acc.append(round(accuracy_score(y_pred,y_test)*100,4))\n    mod_features.append(randForest.feature_importances_)\n\nfor i in range(len(mod_features)):    \n    col = pd.Series(x_train.columns.values)\n    imp = pd.Series(mod_features[i])\n    features = pd.concat([col,imp],axis=1,keys=['Features','Values'])\n    plt.subplot(1,3,(i+1))\n    plt.barh(features['Features'],features['Values'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Comparing all the models**"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}